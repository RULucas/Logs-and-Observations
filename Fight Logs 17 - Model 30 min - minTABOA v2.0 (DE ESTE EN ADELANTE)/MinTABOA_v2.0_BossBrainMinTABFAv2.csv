Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
5000,1.3055255e-05,19134.47,2357650.5,0.12596302,1.0000001e-05,-1.0,2383.0,-1.0
10000,1.3055208e-05,18820.826,2736252.5,0.11812259,1.0000001e-05,-1.0,2434.0,-1.0
15000,1.3055209e-05,18420.146,2311227.2,0.119780935,1.0000001e-05,-1.0,2299.0,-1.0
20000,1.3055209e-05,17993.299,2576356.5,0.12040478,1.0000001e-05,-1.0,2581.5,-1.0
25000,1.3055208e-05,17569.656,2460793.8,0.12220714,1.0000001e-05,-1.0,2236.3333333333335,-1.0
30000,1.3055209e-05,17130.63,2334551.0,0.13106605,1.0000001e-05,-1.0,2082.5,-1.0
35000,1.3055208e-05,16720.219,1846395.8,0.12891617,1.0000001e-05,-1.0,2065.0,-1.0
40000,1.3055208e-05,16289.568,1728029.1,0.1270874,1.0000001e-05,-1.0,3007.5,-1.0
45000,1.3055209e-05,15847.9795,1859588.6,0.12425286,1.0000001e-05,-1.0,2206.0,-1.0
50000,1.3055208e-05,15445.242,1543295.0,0.11586445,1.0000001e-05,-1.0,2434.0,-1.0
55000,1.3055207e-05,15036.473,1710588.2,0.12252882,1.0000001e-05,-1.0,2247.0,-1.0
60000,1.3055208e-05,14623.937,1488930.6,0.12423047,1.0000001e-05,-1.0,2219.5,-1.0
65000,1.3055209e-05,14173.161,1489875.5,0.11657481,1.0000001e-05,-1.0,2123.3333333333335,-1.0
70000,1.3055208e-05,13772.225,1521705.8,0.123299405,1.0000001e-05,-1.0,2271.5,-1.0
75000,1.3055209e-05,13357.918,1395661.9,0.11970139,1.0000001e-05,-1.0,2242.0,-1.0
80000,1.3055208e-05,12955.754,1189651.0,0.10889259,1.0000001e-05,-1.0,2143.5,-1.0
85000,1.3055207e-05,12512.891,1115175.1,0.13071156,1.0000001e-05,-1.0,2058.6666666666665,-1.0
90000,1.3055209e-05,12093.346,1167549.8,0.12835515,1.0000001e-05,-1.0,3656.0,-1.0
95000,1.3055209e-05,11692.409,910222.5,0.13164662,1.0000001e-05,-1.0,2877.0,-1.0
100000,1.3055208e-05,11241.228,1022904.7,0.11946142,1.0000001e-05,-1.0,2136.0,-1.0

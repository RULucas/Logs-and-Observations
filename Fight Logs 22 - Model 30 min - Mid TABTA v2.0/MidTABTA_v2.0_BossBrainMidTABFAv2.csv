Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
22000,1.3174416e-05,40987.926,-1.0,2064.8,-1.0
44000,1.3174416e-05,41007.21,-1.0,2061.7,-1.0
66000,1.3174416e-05,41008.16,-1.0,2052.0,-1.0
88000,1.3174416e-05,41007.652,-1.0,2056.9,-1.0
110000,1.3174416e-05,41007.867,-1.0,2060.8,-1.0
132000,1.3174417e-05,41009.574,-1.0,2061.1,-1.0
154000,1.3174416e-05,41008.023,-1.0,2056.7,-1.0
176000,1.3174416e-05,41006.74,-1.0,2060.4545454545455,-1.0
198000,1.3174417e-05,41009.117,-1.0,2062.4545454545455,-1.0
220000,1.3174416e-05,40544.285,-1.0,2063.0,-1.0
242000,1.3174416e-05,40222.85,-1.0,2060.0,-1.0
264000,1.3174417e-05,40226.06,-1.0,2055.8333333333335,-1.0
286000,1.3174416e-05,40222.367,-1.0,2064.090909090909,-1.0
308000,1.3174416e-05,40222.836,-1.0,2054.7272727272725,-1.0
330000,1.31744155e-05,40222.383,-1.0,2060.3636363636365,-1.0
352000,1.3174417e-05,40221.652,-1.0,2062.4,-1.0
374000,1.3174416e-05,40220.52,-1.0,2056.4,-1.0
396000,1.3174417e-05,40222.062,-1.0,2057.9,-1.0
418000,1.3174416e-05,40033.617,-1.0,2053.3,-1.0
440000,1.3174416e-05,39434.73,-1.0,2057.6,-1.0
462000,1.31744155e-05,39433.03,-1.0,2065.4,-1.0
484000,1.3174416e-05,39431.17,-1.0,2057.2,-1.0
506000,1.3174416e-05,39433.34,-1.0,2064.5454545454545,-1.0
528000,1.3174416e-05,39432.934,-1.0,2059.9166666666665,-1.0
550000,1.3174416e-05,39433.844,-1.0,2062.4545454545455,-1.0
572000,1.3174416e-05,39435.418,-1.0,2060.4545454545455,-1.0
594000,1.3174416e-05,39435.03,-1.0,2062.5,-1.0
616000,1.3174416e-05,39433.41,-1.0,2061.181818181818,-1.0
638000,1.3174417e-05,38788.918,-1.0,2058.6363636363635,-1.0
660000,1.3174416e-05,38679.938,-1.0,2059.2727272727275,-1.0
682000,1.3174416e-05,38680.703,-1.0,2057.6,-1.0
704000,1.3174417e-05,38679.953,-1.0,2055.3,-1.0
